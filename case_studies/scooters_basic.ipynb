{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scooter sharing in Austin, Texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cities around the world, micromobility in the form of\n",
    "electric scooters has recently become very popular.  The city of\n",
    "Austin, Texas has made trip-level data available from all scooter\n",
    "companies operating in the city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first notebook that we see in Stats 206, so we are\n",
    "mainly focused here on introducing the software tools and doing some\n",
    "very basic summarization of the data.  There are a lot of new\n",
    "programming concepts below, and some of them are deliberately only\n",
    "explained at a high level.  We will revisit many of these concepts\n",
    "later in the course and discuss them in greater detail at that time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is a general-purpose programming language.  On its own, it\n",
    "can be used for some basic tasks.  But most of the time, when\n",
    "working with Python, you will be importing _modules_ containing code\n",
    "written by other people that will help you perform more specialized\n",
    "tasks.  For scientific computing and data science, we almost always\n",
    "import the following modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we will often need the \"os\" (operating system) module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scooter data are in a format called \"csv\", which means \"comma\n",
    "separted values\".  This is the standard portable text-based format\n",
    "for rectangular data (data arranged in a table with rows and\n",
    "columns).  The \"pandas\" package, imported above, provides data\n",
    "management and basic data analysis capabilities in Python.  The\n",
    "central element of Pandas is a \"dataframe\", which is a rectangular\n",
    "structure for holding data.\n",
    "\n",
    "Our first step here is to read the data from a csv format file, and\n",
    "represent it in the computer's memory as a dataframe.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, modify this string according to your section number (001 or 002):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"stats206s002f21\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Pandas can read the data using the line of code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/scratch/%s_class_root/%s_class/shared_data/datasets\" % (f, f)\n",
    "df = pd.read_csv(os.path.join(base, \"scooters_short.csv.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command creates a dataframe holding the scooter trip data,\n",
    "and gives it the name `df` which we can use to refer to it later.\n",
    "The `base` variable holds the file path to the location on\n",
    "greatlakes where the data are stored.\n",
    "\n",
    "In the above commands, the values enclosed in quotation marks are\n",
    "\"strings\".  A string is a value that contains text or characters.\n",
    "In this case, the text contained in the string is the \"path\" to the\n",
    "csv-format data that we wish to load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also that the filename above ends with \".gz\".  This indicates\n",
    "that the data are compressed so that the file takes up less space on\n",
    "the disk.  Pandas will automatically decompress the file when\n",
    "reading it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe that we just loaded contains all trips for a random\n",
    "selection of 20,000 scooters from the complete Austin mobility\n",
    "dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting some basic information about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset loaded, we can do some basic things\n",
    "with it.  First, we will get the shape, or dimensions of the\n",
    "dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape attribute contains the number of rows and the number of\n",
    "columns in the dataframe.  This dataset is a subset containing about\n",
    "one quarter of the complete Austin e-mobility dataset.  Right now,\n",
    "it is sufficient to work with this subset, but later in the course\n",
    "we may use the full data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like most rectangular datasets, the rows of this dataset represent\n",
    "cases and the columns represent variables.  A case here is a single\n",
    "trip on a rented scooter.  The columns (variables) provide\n",
    "information about the trip.  Next we will see what the names of the\n",
    "variables are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these variable names are self-explanatory, for others, we\n",
    "will explain their meaning later as needed.  The next line of code\n",
    "displays the first few rows of the dataframe.  Depending on the\n",
    "width of your screen, it is possible that only a subset of the\n",
    "columns will be shown, in which case the omitted columns are\n",
    "displayed as \"...\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the preceeding two code cells, one of them ends with\n",
    "parentheses \"()\" and one does not.  Python uses the dot (\".\") symbol\n",
    "to access two different types of components of a value -- \"methods\"\n",
    "and \"attributes\".  Methods are essentially functions, and functions\n",
    "take arguments inside a pair of parentheses.  Attributes are not\n",
    "functions, and therefore do not have parentheses.  Since `head` is a\n",
    "method, it must be called with parentheses (although here we are not\n",
    "passing any arguments so the parentheses are empty).  `columns` is\n",
    "an attribute, so it does not take parentheses.  It is an error to\n",
    "use parenthes on an attribute, or to omit the parentheses on a\n",
    "method.  To avoid such errors, you will need to learn where you have\n",
    "an attribute and where you have a method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head` method takes an optional argument, which is the number of\n",
    "rows to display.  The default value of this argument is 5, so if we\n",
    "call the method without any arguments, like above, we see five rows\n",
    "of data.  If we want to see a different number of rows, we can pass\n",
    "an argument like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"device ID\" is a unique identifier for each scooter. The number\n",
    "of times that a device ID appears in the dataframe is the number of\n",
    "times that the scooter was rented during the period of time covered\n",
    "by the dataset.  Most of the device IDs appear multiple times in the\n",
    "data set, since most of the scooters were rented multiple times.  To\n",
    "learn more about the device IDs, we can select the column of the\n",
    "dataframe containing these values using the syntax `df[\"Device\n",
    "ID\"]`.  This syntax creates a \"series\" since it contains data for\n",
    "only one variable. The `unique` method then constructs another\n",
    "series containing only the unique device IDs, and the size attribute\n",
    "of this series tells us how many elements it contains.  Thus, the\n",
    "following line of code tells us how many unique scooters are\n",
    "represented in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Device ID\"].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code uses \"chaining\" to do three things in one line of\n",
    "code.  It may be instructive to see how this can be done in three\n",
    "lines, without chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"Device ID\"]\n",
    "y = x.unique()\n",
    "y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at some summary statistics of how many times each\n",
    "scooter was rented.  The `value_counts` method determines all of the\n",
    "distinct values in a series and counts how many times each occurs.\n",
    "The `describe` method then produces a set of summary statistics for\n",
    "these counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Device ID\"].value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Pandas reads a CSV file, the date and time variables are\n",
    "usually not automatically converted to proper Pandas format.  The\n",
    "`dtypes` attribute tells us the storage format of each variable in\n",
    "the dataframe.  We can see below that the \"Start Time\" and \"End\n",
    "Time\" variables have `object` storage format. To work with these\n",
    "variables as time values we will want to convert them to proper\n",
    "\"datetime\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code performs this conversion for the \"Start\n",
    "Time\" variable.  Don't worry about the details of this conversion at\n",
    "the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"%m/%d/%Y %I:%M:%S %p\"\n",
    "df[\"Start Time\"] = pd.to_datetime(df[\"Start Time\"], format=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this variable in a proper format, we can determine\n",
    "the period of time covered by this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Start Time\"].min())\n",
    "print(df[\"Start Time\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the use of `print` above -- the `print` function is used\n",
    "to print a value to the notebook output cell.  By default, the value\n",
    "of the last expression in any code cell is always printed.  If you\n",
    "want to print more than one value from within a single code cell,\n",
    "you should use the `print` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scooter lifespan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question that is often asked about scooter rentals is how long\n",
    "the scooters stay in the fleet.  In some cities, scooters have not\n",
    "lasted very long before breaking or being stolen or lost.  To\n",
    "address this question, we can look at the earliest and last rental\n",
    "of each scooter in the dataset.  We do this by creating a \"grouped\n",
    "dataframe\" with the `groupby` method.  Grouped dataframes are very\n",
    "powerful and we will use them frequently in this course.  We will\n",
    "explain how grouped dataframes work in more detail later.  This\n",
    "example is an introduction to show how grouped dataframes can be\n",
    "used to achieve our current goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df.groupby(\"Device ID\")[\"Start Time\"].agg([np.min, np.max])\n",
    "print(dx.columns)\n",
    "dx[\"duration\"] = dx[\"amax\"] - dx[\"amin\"]\n",
    "print(df.shape, dx.shape)\n",
    "dx[\"duration\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`groupby` carries out a stratification of the data.  In this case,\n",
    "we are stratifying the data by the `Device ID` variable.  Every\n",
    "distinct value of `Device ID` forms a group.  A group contains all\n",
    "trips recorded for one scooter.  We then select only the `Start\n",
    "Time` variable.  Finally, the `agg` method is used to carry out an\n",
    "aggregation or summarization of the data for each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions passed as arguments to `agg()` are the functions used\n",
    "to do the aggregation.  Here we are aggregating using the `min` and\n",
    "`max` functions. These will give us the minimum (earliest) and\n",
    "maximum (latest) trip for each scooter.  The `np.` is placed in\n",
    "front of the `min` and `max` functions because they are part of the\n",
    "numpy package, which we imported above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it can be hard to know what names the variables created by\n",
    "the aggregation will have.  Therefore, we print the names and see\n",
    "here that they are \"amax\" and \"amin\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also printed the shapes of the two dataframes `df` and `dx`.\n",
    "Here, `df` is the original dataframe that we loaded from a csv file,\n",
    "and `dx` is the summarized dataframe containing one row for each\n",
    "distinct device ID.  Since there are 20,000 scooters in the dataset,\n",
    "this summarized dataframe contains exactly 20,000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the minimum and maximum rental date per scooter, we can\n",
    "subtract them to get the duration of time between the first and last\n",
    "rental.  Then, we use the `describe` method to get some basic\n",
    "summary information about these durations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the median scooter only seems to have been used for a\n",
    "period of 55 days.  Note that this is a biased estimate of the\n",
    "actual median lifespan due to \"truncation\" and \"censoring\".  We\n",
    "won't define these terms precisely here, but they refer to the fact\n",
    "that some scooters were in use before and/or after the period of\n",
    "time covered by this dataset, so their actual lifespan is longer\n",
    "than the value calculated here.  There are more advanced statistical\n",
    "methods that can be used to correct for this bias, but we will not\n",
    "pursue that here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scooter usage over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of scooters varies throughout the year, and over the span\n",
    "of several years.  Scooter usage also varies by time of day and day\n",
    "of week, but this is a separate topic that we will revisit later.\n",
    "To focus on the longer term variation in scooter usage, we create a\n",
    "variable below that counts the total number of trips taken during\n",
    "each week within the dataset.  We have around two year's of data, so\n",
    "there are slightly more than 100 weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomplish this goal, we will add two new columns to the\n",
    "dataframe, one containing the year in which the trip occured, and\n",
    "one containing the week within the year that the trip occured (which\n",
    "is an integer between 1 and 52).  Since we already have the start\n",
    "time of each trip, we only need to exract the year and week from the\n",
    "start time, as shown below.  The `dt` symbol is a special attribute\n",
    "of datetime variables that allows us to do things that only make\n",
    "sense with date and/or time values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = df[\"Start Time\"].dt.year\n",
    "df[\"weekofyear\"] = df[\"Start Time\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a variables indicating the year and week of each\n",
    "trip, we can use `groupby` to count how many trips occur for each\n",
    "combination of a year and a week.  Note that here, unlike above, we\n",
    "are grouping by two variables, which must be placed in a list using\n",
    "square brackets (`[]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df.groupby([\"year\", \"weekofyear\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are taking advantage of the built in `size` aggregation\n",
    "method.  This gives us the number of rows per group, which is\n",
    "equivalent to the number of trips per week.  The same result can be\n",
    "obtained using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxx = df.groupby([\"year\", \"weekofyear\"])[\"Device ID\"].agg(np.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that these two series are equal, we can use the\n",
    "following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all(dx == dxx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would make most sense to graph these counts, but we are not\n",
    "introducing graphing yet in this notebook, so we will simply display\n",
    "the counts in a table.  Since our grouped dataframe here groups by\n",
    "two variables, we have what is called a \"hierarchical index\".  We\n",
    "could view the result (`dx`) directly, but to make it easier to read\n",
    "the table, we can \"unstack\" it to produce a table in which the rows\n",
    "are years and the columns are weeks.  This will be a 3 x 52 table\n",
    "since we have at least some data in each of three years.  For\n",
    "viewing on the screen, it is better to have a table that is longer\n",
    "rather than wider, so we use the transpose (`T`) attribute to put\n",
    "the weeks in the rows and the years in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx.unstack().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the result of the above cell, a `NaN` (\"not a number\") will\n",
    "appear in any cell that has no data.  This includes some cells in\n",
    "the future relative to when the data were obtained, and some earlier\n",
    "cells for which no data are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that scooter usage increased rapidly in late summer\n",
    "of 2018 and remained very popular until late fall of 2019.  Note the\n",
    "spike in week 11 of 2019, corresponding to the \"South by Southwest\"\n",
    "event.  By late fall of 2019 and into the early winter of 2020,\n",
    "scooter usage had dropped by around half relative to the same period\n",
    "in the previous year.  Then around week 12 of 2020, the COVID\n",
    "pandemic reached the US, and scooter usage plumetted (although not\n",
    "to zero).  By the end of the data series in the summer of 2020,\n",
    "usage had recovered slightly, but only to around 15% of usage in the\n",
    "previous year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another characteristic of interest is the length of time of each\n",
    "trip.  We can get this by subtracting the start time from the end\n",
    "time for each trip.  But first we will convert the end time to a\n",
    "proper datetime format, like we did for the start time earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"%m/%d/%Y %I:%M:%S %p\"\n",
    "df[\"End Time\"] = pd.to_datetime(df[\"End Time\"], format=f)\n",
    "df[\"Duration\"] = df[\"End Time\"] - df[\"Start Time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `describe` again to obtain some basic summary\n",
    "information, but this mainly reveals that there are some issues with\n",
    "the data.  This is extremely common with administrative data such as\n",
    "we have here.  For example, we see that the longest trip was several\n",
    "weeks long, and the shortest trip had a negative duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Duration\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at all the distinct duration values, we see that they are\n",
    "all in 15 minute increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Duration\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The start time and end time values are rounded in the data to the\n",
    "nearest quarter hour, so that very short trips will be recorded as\n",
    "having zero duration.  The next cell shows what proportion of the\n",
    "trips are recorded as beginning and ending at the same (rounded)\n",
    "time point, and thus having a reported duration of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du = df[\"Duration\"]\n",
    "(du == pd.to_timedelta(0)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we use the `mean` method to calculate a\n",
    "proportion, and we use the `to_timedelta` function to create a time\n",
    "duration with zero length to use in the comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantiles (compared to moments such as the mean) tend to be less\n",
    "affected by data errors (as long as there aren't too many of them).\n",
    "We can look at a few of the quantiles below, and we see that many of\n",
    "the lower quantiles have zero duration, and the median duration is\n",
    "15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more concise way to obtain these same quantiles is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.arange(0.1, 0.91, 0.1)\n",
    "du.quantile(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `np.arange(a, b, c)` creates a sequence of\n",
    "regularly-spaced values, starting at `a`, increasing in steps of\n",
    "`c`, and continuing as long as the value is less than `b`.  Note\n",
    "that to include 0.9 in the list, the value of `b` must be strictly\n",
    "larger than 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the vast majority of trips are under 30 minutes.  To see\n",
    "the longer trips, we will want to look at more extreme quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.quantile([0.95, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us, for example, that around 1 in 100 trips lasts one\n",
    "hour or longer."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
