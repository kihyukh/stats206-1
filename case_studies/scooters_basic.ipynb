{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scooter sharing in Austin, Texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cities around the world, micromobility in the form of\n",
    "electric scooters has recently become very popular.  The city of\n",
    "Austin, Texas has made available trip-level data from all scooter\n",
    "companies operating within the city limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first notebook that we see in Stats 206.  We are mainly\n",
    "focused here on introducing the software tools and doing some very\n",
    "basic summarization and description of the data.  There are a lot of\n",
    "new programming concepts below, and some of them are deliberately\n",
    "only explained at a high level.  We will revisit many of these\n",
    "concepts later in the course and discuss them in greater detail at\n",
    "that time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is a general-purpose programming language.  On its own, it\n",
    "can be used for some basic tasks.  Most of the time, when working\n",
    "with Python, you will be importing _modules_ containing code that is\n",
    "not part of the core Python language, that will help you perform\n",
    "more specialized tasks.  For scientific computing and data science,\n",
    "we almost always import the numpy and pandas modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we will often need the \"os\" (operating system) module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scooter data are in a format called \"csv\", which stands for\n",
    "\"comma separated values\".  This is the most common portable\n",
    "text-based format for rectangular data (data arranged in a table\n",
    "with rows and columns).  The \"pandas\" package, imported above,\n",
    "provides data management and basic data analysis capabilities in\n",
    "Python.  The central element of Pandas is a \"dataframe\", which is a\n",
    "rectangular structure for holding data.\n",
    "\n",
    "Our first step here is to read the data from a csv format file\n",
    "containing the scooter trips, and represent it in the computer's\n",
    "memory as a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, modify this string according to your section number (001 or\n",
    "002):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"stats206s002f21\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Pandas can read the data using the line of code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/scratch/%s_class_root/%s_class/shared_data/datasets\" % (f, f)\n",
    "df = pd.read_csv(os.path.join(base, \"scooters_short.csv.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above commands create a dataframe holding the scooter trip data,\n",
    "and creates a variable named `df` that is bound to this value.\n",
    "\n",
    "In the above commands, the values enclosed in quotation marks are\n",
    "\"strings\".  A string is a value that contains a sequence of text or\n",
    "characters.  In this case, the string bound to the \"base\" variable\n",
    "is the \"file path\" pointing to the CSV file on greatlakes that we\n",
    "wish to load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also that the filename above ends with \".gz\".  This indicates\n",
    "that the data are compressed so that the file takes up less space on\n",
    "the disk.  Pandas will automatically decompress the file when\n",
    "reading it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe that we just loaded contains all trips for a random\n",
    "selection of 20,000 scooters drawn from the complete Austin mobility\n",
    "dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting some basic information about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset loaded, we can do some basic things\n",
    "with it.  First, we will get the shape, or dimensions of the\n",
    "dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape attribute contains the number of rows and the number of\n",
    "columns in the dataframe.  This dataset is a subset containing about\n",
    "one quarter of the complete Austin e-mobility dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like most rectangular datasets, the rows of this dataset represent\n",
    "cases and the columns represent variables.  A case here is a single\n",
    "trip on a rented scooter.  The columns (variables) provide\n",
    "information about the trip.  Next we will see what the names of the\n",
    "variables are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these variable names are self-explanatory, for others, we\n",
    "will explain their meaning below as needed.  The next line of code\n",
    "displays the first few rows of the dataframe.  Depending on the\n",
    "width of your screen, it is possible that only a subset of the\n",
    "columns will be shown, in which case the omitted columns are\n",
    "displayed as \"...\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the preceeding two code cells, \"head\" is followed by\n",
    "parentheses and \"columns\" is not. This is because \"head\" is a method\n",
    "while \"columns\" is an attribute.  Methods are essentially functions,\n",
    "and functions take arguments inside a pair of parentheses.\n",
    "Attributes are not functions, and therefore do not have parentheses.\n",
    "It is an error to use parentheses on an attribute, or to omit the\n",
    "parentheses on a method.  To avoid such errors, you will need to\n",
    "learn when you have an attribute and when you have a method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head` method takes an optional argument, which is the number of\n",
    "rows to display.  The default value of this argument is 5, so if we\n",
    "call the method without any arguments, like above, we see five rows\n",
    "of data.  If we want to see a different number of rows, we can pass\n",
    "an argument like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"device ID\" is a unique identifier for each scooter. The number\n",
    "of times that a device ID appears in the dataframe is the number of\n",
    "times that the scooter was rented during the period of time covered\n",
    "by the dataset.  Most of the device IDs appear multiple times in the\n",
    "data set, since most of the scooters were rented multiple times.\n",
    "\n",
    "To learn more about the device IDs, we can select the column of the\n",
    "dataframe containing these values using the syntax `df[\"Device\n",
    "ID\"]`.  This creates a \"series\" since it contains data for only one\n",
    "variable. The `unique` method then constructs another series\n",
    "containing only the unique device IDs, and the `size` attribute of\n",
    "this series tells us how many elements it contains.  Thus, the\n",
    "following line of code tells us how many unique scooters are\n",
    "represented in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Device ID\"].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code uses \"chaining\" to do three things in one line of\n",
    "code.  It may be instructive to see how this can be done in three\n",
    "lines, without chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"Device ID\"]\n",
    "y = x.unique()\n",
    "y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at some summary statistics of how many times each\n",
    "scooter was rented.  The `value_counts` method determines all of the\n",
    "distinct values in a series and counts how many times each occurs.\n",
    "The `describe` method then produces a set of summary statistics for\n",
    "these counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Device ID\"].value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Pandas reads a CSV file, the date and time variables are\n",
    "usually not automatically converted to proper Pandas format.  The\n",
    "`dtypes` attribute tells us the storage format of each variable in\n",
    "the dataframe.  We can see below that the \"Start Time\" and \"End\n",
    "Time\" variables have `object` storage format. To work with these\n",
    "variables as time values we will want to convert them to \"datetime64\"\n",
    "values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code perform this conversion for the \"Start\n",
    "Time\" variable.  Don't worry about the details of this conversion at\n",
    "the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"%m/%d/%Y %I:%M:%S %p\"\n",
    "df[\"Start Time\"] = pd.to_datetime(df[\"Start Time\"], format=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the types again and see that `Start Time` has type\n",
    "\"datetime64\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this variable in a proper format, we can determine\n",
    "the period of time covered by this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Start Time\"].min())\n",
    "print(df[\"Start Time\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the use of `print` above -- the `print` function is used\n",
    "to print a value to the notebook output cell.  By default, the value\n",
    "of the last expression in any code cell is always printed.  If you\n",
    "want to print more than one value from within a single code cell,\n",
    "you should use the `print` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scooter lifespan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question that is often asked about scooter rentals is how long\n",
    "the scooters stay in the fleet.  In some cities, scooters have\n",
    "generally not lasted very long before breaking or being stolen or\n",
    "lost.  To address this question, we can look at the earliest and\n",
    "last rental of each scooter in the dataset.  We do this by creating\n",
    "a \"grouped dataframe\" with the `groupby` method.  Grouped dataframes\n",
    "are very powerful and we will use them frequently in this course.\n",
    "We will explain how grouped dataframes work in more detail later.\n",
    "This example is an introduction to show how grouped dataframes can\n",
    "be used to achieve our current goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df.groupby(\"Device ID\")[\"Start Time\"].agg([np.min, np.max])\n",
    "print(dx.columns)\n",
    "dx[\"duration\"] = dx[\"amax\"] - dx[\"amin\"]\n",
    "print(df.shape, dx.shape)\n",
    "dx[\"duration\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`groupby` carries out a stratification of the data.  In this case,\n",
    "we are stratifying the data by the `Device ID` variable.  Every\n",
    "distinct value of `Device ID` forms a group.  A group contains all\n",
    "trips recorded for one scooter.  We then select only the `Start\n",
    "Time` variable.  Finally, the `agg` method is used to carry out an\n",
    "aggregation or summarization of the data for each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions passed as arguments to `agg()` are the functions used\n",
    "to do the aggregation.  Here we are aggregating using the `min` and\n",
    "`max` functions. These will give us the minimum (earliest) and\n",
    "maximum (latest) trip for each scooter.  The `np.` is placed in\n",
    "front of the `min` and `max` functions because they are part of the\n",
    "numpy package, which we imported above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it can be hard to know what names the variables created by\n",
    "the aggregation will have.  Therefore, we print the names and see\n",
    "here that they are \"amax\" and \"amin\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also printed the shapes of the two dataframes `df` and `dx`.\n",
    "Here, `df` is the original dataframe that we loaded from a csv file,\n",
    "and `dx` is the summarized dataframe containing one row for each\n",
    "distinct device ID.  Since there are 20,000 scooters in the dataset,\n",
    "this summarized dataframe contains exactly 20,000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the minimum and maximum rental date per scooter, we can\n",
    "subtract them to get the duration of time between the first and last\n",
    "rental.  Then, we use the `describe` method to get some basic\n",
    "summary information about these durations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the median scooter was used for a period of 82 days.\n",
    "Note that this is a biased estimate of the actual median lifespan\n",
    "due to \"truncation\" and \"censoring\".  We won't define these terms\n",
    "precisely here, but they refer to the fact that some scooters were\n",
    "in use before and/or after the period of time covered by this\n",
    "dataset, so their actual lifespan is longer than the value\n",
    "calculated here.  There are more advanced statistical methods that\n",
    "can be used to correct for this bias, but we will not pursue that\n",
    "here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scooter usage over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of scooters varies throughout the year, and over the span\n",
    "of several years.  Scooter usage also varies by time of day and day\n",
    "of week, but this is a separate topic that we will revisit later.\n",
    "To focus on the longer term variation in scooter usage, we create a\n",
    "variable below that counts the total number of trips taken during\n",
    "each week within the dataset.  We have around two year's of data, so\n",
    "there are slightly more than 100 weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomplish this goal, we will add two new columns to the\n",
    "dataframe, one containing the year in which the trip occured, and\n",
    "one containing the week within the year that the trip occured (which\n",
    "is an integer between 1 and 52).  Since we already have the start\n",
    "time of each trip, we only need to exract the year and week from the\n",
    "start time, as shown below.  The `dt` symbol is a special attribute\n",
    "of datetime variables that allows us to do things that only make\n",
    "sense with date and/or time values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = df[\"Start Time\"].dt.year\n",
    "df[\"weekofyear\"] = df[\"Start Time\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a variables indicating the year and week of each\n",
    "trip, we can use `groupby` to count how many trips occur for each\n",
    "combination of a year and a week.  Note that here, unlike above, we\n",
    "are grouping by two variables, which must be placed in a list using\n",
    "square brackets (`[]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df.groupby([\"year\", \"weekofyear\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are taking advantage of the built in `size` aggregation\n",
    "method.  This gives us the number of rows per group, which is\n",
    "equivalent to the number of trips per week.  The same result can be\n",
    "obtained using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxx = df.groupby([\"year\", \"weekofyear\"])[\"Device ID\"].agg(np.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that these two series are equal, we can use the\n",
    "following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all(dx == dxx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would make most sense to graph these counts, but we are not\n",
    "introducing graphing yet in this notebook, so we will simply display\n",
    "the counts in a table.  Since our grouped dataframe here groups by\n",
    "two variables, we have what is called a \"hierarchical index\".  We\n",
    "could view the result (`dx`) directly, but to make it easier to read\n",
    "the table, we can \"unstack\" it to produce a table in which the rows\n",
    "are years and the columns are weeks.  This will be a 4 x 52 table\n",
    "since we have at least some data in each of four years.  For viewing\n",
    "on the screen, it is better to have a table that is longer rather\n",
    "than wider, so we use the transpose (`T`) attribute to put the weeks\n",
    "in the rows and the years in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx.unstack().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the result of the above cell, a `NaN` (\"not a number\") will\n",
    "appear in any cell that has no data.  This includes some cells that\n",
    "fall in the future relative to when the data were obtained, and some\n",
    "earlier cells for which no data are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that scooter usage increased rapidly in late summer\n",
    "of 2018 and remained very popular until late fall of 2019.  Note the\n",
    "spike in week 11 of 2019, corresponding to the \"South by Southwest\"\n",
    "event.  By late fall of 2019 and into the early winter of 2020,\n",
    "scooter usage had dropped by around half relative to the same period\n",
    "in the previous year.  Then around week 12 of 2020, the COVID\n",
    "pandemic reached the US, and scooter usage plumetted (although not\n",
    "to zero).  By the end of the data series in the summer of 2020,\n",
    "usage had recovered slightly, but only to around 15% of usage in the\n",
    "previous year.  In 2021, scooter usage remained somewhat lower than\n",
    "pre-pandemic levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another characteristic of interest is the length of time of each\n",
    "scooter trip. The `Trip Duration` variable contains this information\n",
    "in units of seconds.  Suppose we wish to calculate some basic \n",
    "summary statistics for the trip durations for trips taken each \n",
    "month.  The `describe` method calculates many common summary\n",
    "statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Month\")[\"Trip Duration\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to calculate a particular summary statistic, for example\n",
    "several quantiles, we can proceed as below.  Note that by dividing\n",
    "the results by 60, the units become minutes rather than seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Month\")[\"Trip Duration\"].quantile([0.5, 0.9]).unstack() / 60"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
